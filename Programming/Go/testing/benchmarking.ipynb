{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking (Go)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading list\n",
    "\n",
    "* https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments\n",
    "\n",
    "* __-bench__ `regexp` - run only benchmarks matching regexp\n",
    "* __-benchmem__ - print memory allocations for benchmarks\n",
    "* __-benchtime__ `d` - run each benchmark for duration d (default `1s`)\n",
    "* __-blockprofile__ `file` - write a goroutine blocking profile to file\n",
    "* __-blockprofilerate__ `rate` - set blocking profile rate (see `runtime.SetBlockProfileRate`) (default `1`)\n",
    "* __-count__ `n` - run tests and benchmarks n times (default 1)\n",
    "* __-coverprofile__ `file` - write a coverage profile to file\n",
    "* __-cpu__ `list` - comma-separated list of cpu counts to run each test with\n",
    "* __-cpuprofile__ `file` - write a cpu profile to file\n",
    "* __-failfast__ - do not start new tests after the first test failure\n",
    "* __-list__ `regexp` - list tests, examples, and benchmarks matching regexp then exit\n",
    "* __-memprofile__ `file` - write an allocation profile to file\n",
    "* __-memprofilerate__ `rate` - set memory allocation profiling rate (see runtime.MemProfileRate)\n",
    "* __-mutexprofile__ `string` - write a mutex contention profile to the named file after execution\n",
    "* __-mutexprofilefraction__ `int` - if >= 0, calls runtime.SetMutexProfileFraction() (default `1`)\n",
    "* __-outputdir__ `dir` - write profiles to dir\n",
    "* __-parallel__ `n` - run at most n tests in parallel (default `24`)\n",
    "* __-run__ `regexp` - run only tests and examples matching regexp\n",
    "* __-short__ - \trun smaller test suite to save time\n",
    "* __-testlogfile__ `file` - \twrite test action log to file (for use only by `cmd/go`)\n",
    "* __-timeout__ `d` - panic test binary after duration d (default `0`, timeout disabled)\n",
    "* __-trace__ `file` - write an execution trace to file\n",
    "* __-v__ - verbose: print additional output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on compiler optimisations\n",
    "\n",
    "Before concluding I wanted to highlight that to be completely accurate, any benchmark should be careful to avoid compiler optimisations eliminating the function under test and artificially lowering the run time of the benchmark.m\n",
    "\n",
    "```go\n",
    "var result int\n",
    "\n",
    "func BenchmarkFibComplete(b *testing.B) {\n",
    "        var r int\n",
    "        for n := 0; n < b.N; n++ {\n",
    "                // always record the result of Fib to prevent\n",
    "                // the compiler eliminating the function call.\n",
    "                r = Fib(10)\n",
    "        }\n",
    "        // always store the result to a package level variable\n",
    "        // so the compiler cannot eliminate the Benchmark itself.\n",
    "        result = r\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Stat for benchmarking\n",
    " \n",
    "\n",
    "* https://github.com/golang/go/issues/23471\n",
    "* https://godoc.org/golang.org/x/perf/cmd/benchstat\n",
    "* [Go performance measurement, storage, and analysis tools](https://go.googlesource.com/perf/+/83061fdb061356c976cc90806fa391b09da42568#go-performance-measurement_storage_and-analysis-tools)\n",
    "* https://github.com/golang/go/wiki/Performance\n",
    "* https://blog.codeship.com/real-life-go-benchmarking/\n",
    "\n",
    "```bash\n",
    "# install benchstat                                                           \n",
    "go get -u golang.org/x/perf/cmd/benchstat\n",
    "# running go test with next arguments will run BenchmarkName 10 \n",
    "# times in verbose mode. output will be redirected to results.txt\n",
    "go test ./...  -bench=BenchmarkName -benchmem -run=^$ -count=10 -cpu=1,4  > results.txt\n",
    "\n",
    "# alternativly we can pass regular expression to run all benchmarks \n",
    "go test ./...  -bench='.*' -benchmem -run=^$ -count=10 -cpu=1,4  > results.txt\n",
    "\n",
    "# analyze output\n",
    "benchmark results.txt\n",
    "\n",
    "# more deailed benchmarking with \n",
    "# https://github.com/alecthomas/go_serialization_benchmarks/blob/master/stats.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T20:09:18.350707Z",
     "start_time": "2019-07-25T20:09:18.345576Z"
    }
   },
   "source": [
    "### Timers\n",
    "\n",
    "* https://medium.com/justforfunc/analyzing-the-performance-of-go-functions-with-benchmarks-60b8162e61c6\n",
    "\n",
    "```go\n",
    "func bench(b *testing.B, fnc func(...) ...) {\n",
    "    \n",
    "    // b.ResetTimer() // will reset time and memory allocation.\n",
    "                      // doesn't work if timer is running.\n",
    "    \n",
    "\tb.StopTimer()     // <- Stoping timing test\n",
    "    heavyLifting()    // some setup heavylifting  \n",
    "\tb.StartTimer()    // <- Starting timing test\n",
    "\tb.RunParallel(func(pb *testing.PB) {\n",
    "\t\tfor pb.Next() {\n",
    "\t\t\tvar r int\n",
    "\t\t\tfor _, test := range TestCases {\n",
    "\t\t\t\tr = fnc(...)\n",
    "\t\t\t}\n",
    "\t\t\tresult = r\n",
    "\t\t}\n",
    "\t})\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `b.Run`\n",
    "\n",
    "Sub-Benchmark\n",
    "\n",
    "```go\n",
    "// we can run subbenchmarks in same way as we running subtests...\n",
    "b.Run(Name, func(b *testing.B) {\n",
    "    for i := 0; i < b.N; i++ {\n",
    "        // Our testing fucntionality...\n",
    "    }\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T20:27:53.120722Z",
     "start_time": "2019-07-25T20:27:53.115821Z"
    }
   },
   "source": [
    "### Useful to have\n",
    "\n",
    "* `b.ReportAllocs()` - malocs reports"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
